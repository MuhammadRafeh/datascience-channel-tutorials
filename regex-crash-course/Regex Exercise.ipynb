{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80c530fb-03d1-40fa-9e84-7078911ec2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9abd63f1-22c2-469c-bfe6-9011b30a6138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome', 'intelligent', 'awesome', 'intelligent']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all patterns that match -> awesome or intelligent\n",
    "\n",
    "text = \"this is awesome. This is intelligent. This is not awesome. This is not intelligent\"\n",
    "\n",
    "re.findall(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d935515-aa96-4363-ad5c-0bb9aeb0ca4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rafeh.', 'Rafeh', 'Rafeh', 'Rafeh', 'Rafeh']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all patterns that match -> Rafeh. or Rafeh\n",
    "\n",
    "text = \"Rafeh.* is amazing, Rafeh is great, Rafeh is awesome, Rafeh is cool Rafeh\"\n",
    "\n",
    "re.findall('', text) # first way\n",
    "re.findall('', text) # Second way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5e30779-b8dc-4873-8044-44a35ded110c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rafeh.* +is amazing.+']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all the patterns that match -> Rafeh.* +is amazing.+\n",
    "\n",
    "text = \"Rafeh.* +is amazing.+ Rafeh is great, Rafeh is awesome, Rafeh is cool Rafeh\"\n",
    "\n",
    "re.findall(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a90ab6-8c1d-4ce6-ab24-34e1b8c4b0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['f1', 'f1', 'f1']\", \"['f2', 'f2', 'f2']\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab all the lists of food\n",
    "\n",
    "text = \"\"\"\n",
    "food = ['f1', 'f1', 'f1']\n",
    "food = ['f2', 'f2', 'f2']\n",
    "sabzi = ['s1', 's1', 's1']\n",
    "sabzi = ['s2', 's2', 's2']\n",
    "\"\"\"\n",
    "\n",
    "re.findall('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d981423-e2f7-4b99-ac1b-09479710a184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['f1', 'f1', 'f1']\",\n",
       " \"['d1', 'd1', 'd1']\",\n",
       " \"['dess1', 'dess1', 'dess1']\",\n",
       " \"['fr1', 'fr2', 'fr3']\",\n",
       " \"['v1', 'v2', 'v3']\",\n",
       " '[1, 2, 3]',\n",
       " \"['red', 'blue', 'green']\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab everything except animal\n",
    "\n",
    "text = \"\"\"\n",
    "food: ['f1', 'f1', 'f1']\n",
    "drink: ['d1', 'd1', 'd1']\n",
    "dessert: ['dess1', 'dess1', 'dess1']\n",
    "fruit: ['fr1', 'fr2', 'fr3']\n",
    "vegetable: ['v1', 'v2', 'v3']\n",
    "number: [1, 2, 3]\n",
    "color: ['red', 'blue', 'green']\n",
    "animal: ['cat', 'dog', 'rabbit']\n",
    "\"\"\"\n",
    "\n",
    "re.findall('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02fb6072-ec65-4599-b42d-0e78fc95b75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.example.com',\n",
       " 'http://subdomain.example.org/path/page.html',\n",
       " 'ftp://ftp.example.net']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all the urls from the string below\n",
    "# Hint use \\S which matches everything except whitespaces. \n",
    "# Whitespace includes (spaces, tabs, and new line character)\n",
    "\n",
    "text = \"\"\"\n",
    "Here are some URLs in different formats:\n",
    "- https://www.example.com\n",
    "- http://subdomain.example.org/path/page.html\n",
    "- ftp://ftp.example.net\n",
    "Please extract all the above URLs\n",
    "\"\"\"\n",
    "\n",
    "re.findall('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea7fde4-0e21-471f-8781-dfa61d0691dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12/25/2022', '2022-01-15', '05/10/23', '2023-09-06']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all the dates from the string below\n",
    "\n",
    "text = \"\"\"\n",
    "Here are some dates in different formats:\n",
    "- 12/25/2022\n",
    "- 2022-01-15\n",
    "- 05/10/23\n",
    "- 2023-09-06\n",
    "\"\"\"\n",
    "\n",
    "re.findall('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33f963bc-219e-460b-a0da-96c123435b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'userid': '1',\n",
       "  'name': 'John Doe',\n",
       "  'email': 'john@example.com',\n",
       "  'number': '555-123-4567'},\n",
       " {'userid': '2',\n",
       "  'name': 'Alice Smith',\n",
       "  'email': 'alice.smith@email.org',\n",
       "  'number': '(123) 456-7890'},\n",
       " {'userid': '3',\n",
       "  'name': 'Bob Johnson',\n",
       "  'email': 'bobj@example.co.uk',\n",
       "  'number': '444.555.6666'},\n",
       " {'userid': '4',\n",
       "  'name': 'Carol Brown',\n",
       "  'email': 'carol_brown@example.com',\n",
       "  'number': '111 222 3333'},\n",
       " {'userid': '5',\n",
       "  'name': 'David Lee',\n",
       "  'email': 'david@example.net',\n",
       "  'number': '777/888/9999'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all the users from the string below\n",
    "\n",
    "data = \"\"\"\n",
    "User 1:\n",
    "Name: John Doe\n",
    "Email: john@example.com\n",
    "Phone: 555-123-4567\n",
    "\n",
    "User 2:\n",
    "Name: Alice Smith\n",
    "Email: alice.smith@email.org\n",
    "Phone: (123) 456-7890\n",
    "\n",
    "User 3:\n",
    "Name: Bob Johnson\n",
    "Email: bobj@example.co.uk\n",
    "Phone: 444.555.6666\n",
    "\n",
    "User 4:\n",
    "Name: Carol Brown\n",
    "Email: carol_brown@example.com\n",
    "Phone: 111 222 3333\n",
    "\n",
    "User 5:\n",
    "Name: David Lee\n",
    "Email: david@example.net\n",
    "Phone: 777/888/9999\n",
    "\"\"\"\n",
    "\n",
    "pattern = ''\n",
    "user_list = []\n",
    "for match in re.finditer(pattern, data):\n",
    "    user_list.append(match.groupdict())\n",
    "\n",
    "user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea26059-bd76-4d65-a99c-a95a0699d9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Serial Number': 'AB-2023-XYZ1',\n",
       "  'Product Code': 'AB',\n",
       "  'Manufacturing Year': '2023',\n",
       "  'Unique Identifier': 'XYZ1'},\n",
       " {'Serial Number': 'CD-2022-1234',\n",
       "  'Product Code': 'CD',\n",
       "  'Manufacturing Year': '2022',\n",
       "  'Unique Identifier': '1234'},\n",
       " {'Serial Number': 'EF-2024-ABCD',\n",
       "  'Product Code': 'EF',\n",
       "  'Manufacturing Year': '2024',\n",
       "  'Unique Identifier': 'ABCD'},\n",
       " {'Serial Number': 'GH-2025-5678',\n",
       "  'Product Code': 'GH',\n",
       "  'Manufacturing Year': '2025',\n",
       "  'Unique Identifier': '5678'},\n",
       " {'Serial Number': 'IJ-2021-WXYZ',\n",
       "  'Product Code': 'IJ',\n",
       "  'Manufacturing Year': '2021',\n",
       "  'Unique Identifier': 'WXYZ'},\n",
       " {'Serial Number': 'KL-2026-9876',\n",
       "  'Product Code': 'KL',\n",
       "  'Manufacturing Year': '2026',\n",
       "  'Unique Identifier': '9876'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all the Valid Serial Numbers\n",
    "# Example AB-2023-XYZ1\n",
    "# Product Code: AB\n",
    "# Manifacturing Year: 2023 \n",
    "# Product Unique Identifer: XYZ1\n",
    "\n",
    "\n",
    "serial_numbers = [\n",
    "    \"AB-2023-XYZ1\",\n",
    "    \"CD-2022-1234\",\n",
    "    \"EF-2024-ABCD\",\n",
    "    \"Invalid Serial\",\n",
    "    \"GH-2025-5678\",\n",
    "    \"IJ-2021-WXYZ\",\n",
    "    \"KL-2026-9876\",\n",
    "]\n",
    "\n",
    "valid_serial_numbers = []\n",
    "\n",
    "pattern = \"\"\n",
    "\n",
    "for serial in serial_numbers:\n",
    "    match = re.match(pattern, serial)\n",
    "    if match:\n",
    "        product_code = match.group(1)\n",
    "        manufacturing_year = match.group(2)\n",
    "        unique_identifier = match.group(3)\n",
    "        valid_serial_numbers.append({\n",
    "            'Serial Number': serial,\n",
    "            'Product Code': product_code,\n",
    "            'Manufacturing Year': manufacturing_year,\n",
    "            'Unique Identifier': unique_identifier,\n",
    "        })\n",
    "\n",
    "valid_serial_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5397399c-c001-401f-b7b1-3914a2ae661b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2023-09-01 12:30:05', 'Critical error occurred: File not found.'),\n",
       " ('2023-09-01 13:15:20', 'Database connection failed.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract full timestamp and error message. [('2023-09-01 12:30:05'), ('Critical error occurred: File not found.')] but Just need for the errors\n",
    "\n",
    "# Sample log file\n",
    "log_data = \"\"\"\n",
    "[2023-09-01 12:15:00] [INFO] Application started.\n",
    "[2023-09-01 12:30:05] [ERROR] Critical error occurred: File not found.\n",
    "[2023-09-01 12:45:10] [INFO] User logged in.\n",
    "[2023-09-01 13:00:15] [WARNING] Disk space low.\n",
    "[2023-09-01 13:15:20] [ERROR] Database connection failed.\n",
    "[2023-09-01 13:30:25] [INFO] Application shutdown.\n",
    "\"\"\"\n",
    "\n",
    "# Your regular expression pattern to match and extract ERROR log entries\n",
    "pattern = \"\"\n",
    "\n",
    "# Find and extract ERROR log entries\n",
    "re.findall(pattern, log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a66a33-cdd1-48e5-bc42-707252ac8eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[rafeh, ammar, moiz    , amna]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring out the list from the string\n",
    "# Hint: use .\n",
    "\n",
    "text = \" asdasd [rafeh, ammar, moiz    , amna] asdas\"\n",
    "\n",
    "re.findall(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f9ec1fc-82cd-4fd1-b550-ce3798b70d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valid list here', 'this is a valid list', 'valid list here too']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring out all the valid list from the string\n",
    "\n",
    "text = \" asdasd [valid list here] asdas] [this is a valid list]     [valid list here too]\"\n",
    "\n",
    "re.findall(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a52ae617-a7ed-41af-a490-738faa44e94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Set', 'Second Set', 'Third Set']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring out all the content inside all the lists except the list's square brackets\n",
    "\n",
    "text = \"[First Set] Some text [Second Set] [Third Set]\"\n",
    "re.findall(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca4213a-bd37-47f9-b7c5-c4c21433d6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rafeh', 'atique', 'rafeh', 'atique', 'asd', '909asd0909', '2323']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract every digit words except dots and white spaces\n",
    "\n",
    "text = 'rafeh . atique . rafeh . atique . asd . 909asd0909 .2323'\n",
    "\n",
    "re.findall(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd87472c-6ef5-4bd2-ae2c-9bc74aca23a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word1', 'word2', 'word3', 'word_4', 'word_7', 'word_90', 'word', 'word']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the words\n",
    "\n",
    "text = \"word1 word2 word3 word_4 word_7 word_90 word word\"\n",
    "re.findall(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "573e95ad-9352-455c-a8e9-772f8ce42ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Python', '#DataScience', '#MachineLearning']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract All Hashtags:\n",
    "\n",
    "text = \"Check out #Python, #DataScience, and #MachineLearning topics on Twitter.\"\n",
    "re.findall(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b911ec5-063c-43b4-9895-d7c6dc9b0529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John, Alice, Bob']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Names from a String in Square Brackets\n",
    "\n",
    "text1 = \"Hello [John, Alice, Bob], welcome!\"\n",
    "re.findall(\"\", text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e8d7e49-1b77-481c-850b-9b37bb1936fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12, 34, 56']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Numbers from a String in Parentheses\n",
    "\n",
    "text2 = \"Total (12, 34, 56) items in stock.\"\n",
    "re.findall(\"\", text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cea6e798-c3b0-4166-95b0-0c0ca68eb6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python, programming, regex']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Keywords from a String in Curly Braces\n",
    "\n",
    "text3 = \"Search for {Python, programming, regex} in the text.\"\n",
    "re.findall(\"\", text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e809b20b-26cf-44d7-99b2-78453cbef87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New York, Los Angeles, Chicago']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Cities from a String in Angle Brackets\n",
    "\n",
    "text4 = \"Visit our offices in <New York, Los Angeles, Chicago>.\"\n",
    "re.findall(\"\", text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba084e13-b30b-463a-be55-40a8c2388412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item1, item2, item3']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Items from a String in Square Brackets\n",
    "\n",
    "text5 = \"Selected items: [item1, item2, item3].\"\n",
    "re.findall(\"\", text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3ff35ba-8206-4bd5-86eb-f487ee68036e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user1@example.com']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive Lookahead (Matching \".com\" emails)\n",
    "email = \"user1@example.com\"\n",
    "\n",
    "pattern1 = \"\"\n",
    "re.findall(pattern1, email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92533392-a653-4e3a-86e4-99a2c0eb8677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document.txt', 'image.jpg', 'data.csv']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 2: Negative Lookahead (Matching non-.tmp file names)\n",
    "file_list = [\n",
    "    \"document.txt\",\n",
    "    \"image.jpg\",\n",
    "    \"data.csv\",\n",
    "    \"backup.tmp\",\n",
    "]\n",
    "\n",
    "pattern2 = \"\"\n",
    "[file for file in file_list if re.match(pattern2, file)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
